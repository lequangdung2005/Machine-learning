{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,ids=None,children=[],entropy=0,depth=0):\n",
    "        self.ids=ids\n",
    "        self.entropy=entropy\n",
    "        self.depth=depth\n",
    "        self.split_attribute=None # chosen feature to divide into children\n",
    "        self.children=children\n",
    "        self.val_chosen=None      # val_chosen to save values for predictation\n",
    "        self.label=None\n",
    "\n",
    "    def set_val(self,split_attribute,val_chosen):\n",
    "        self.split_attribute=split_attribute\n",
    "        self.val_chosen=val_chosen    # function to save 2 val for predictation\n",
    "\n",
    "    def set_label(self,label):\n",
    "        self.label=label\n",
    "\n",
    "class decision_tree_id3(object):\n",
    "\n",
    "    def __init__(self,max_depth=10,min_sample_split=2,min_gain=1e-4):\n",
    "        self.root=None\n",
    "        self.max_depth=max_depth\n",
    "        self.min_sample_split=min_sample_split\n",
    "        self.Ntrain=0\n",
    "        self.min_gain=min_gain\n",
    "\n",
    "    def optimizer_step(self,data,target):\n",
    "        self.attributes = list(data)    # name features of data\n",
    "        self.Ntrain=data.count().iloc[0]   # number of data\n",
    "        self.data=data\n",
    "        self.target=target\n",
    "        self.labels=target.unique()     \n",
    "        ids=range(self.Ntrain)\n",
    "        self.root=Node(ids=ids,entropy=self.entropy(ids),depth=0)\n",
    "        queue=[self.root]\n",
    "        while queue:\n",
    "            node=queue.pop()\n",
    "            if node.depth<self.max_depth or node.entropy<self.min_gain:\n",
    "                node.children=self._split(node)\n",
    "                if not node.children:\n",
    "                    self._set_label(node)\n",
    "                queue+=node.children\n",
    "            else:\n",
    "                self._set_label(node) \n",
    "\n",
    "    def _split(self,node):\n",
    "        ids=node.ids\n",
    "        best_gain=0\n",
    "        best_splits=[]\n",
    "        best_attributes=None\n",
    "        val_chosen=None\n",
    "        \n",
    "        sub_data=self.data.iloc[ids,:] # sub data of this node\n",
    "        for i, att in enumerate(self.attributes):   \n",
    "            values=sub_data.iloc[:,i].unique().tolist()\n",
    "            if len(values)==1: continue\n",
    "            splits=[]\n",
    "            for value in values:\n",
    "                sub_ids=sub_data.index[sub_data[att]==value].tolist()\n",
    "                splits.append(sub_ids)\n",
    "            if min(map(len,splits))<self.min_sample_split : continue    # map function apply len function for each element of splits\n",
    "            entropy_=0\n",
    "            for split in splits:\n",
    "                entropy_+=len(split)*self.entropy(split)/len(ids)\n",
    "            gain=node.entropy-entropy_\n",
    "            if gain<self.min_gain: continue\n",
    "            if gain>best_gain:\n",
    "                best_gain=gain\n",
    "                best_attributes=att\n",
    "                best_splits=splits\n",
    "                val_chosen=values\n",
    "        node.set_val(best_attributes,val_chosen) \n",
    "        child_nodes=[Node(ids=split,entropy=self.entropy(split),depth=node.depth+1)for split in best_splits]\n",
    "        return child_nodes\n",
    "\n",
    "    def _set_label(self,node): \n",
    "        target_ids=node.ids\n",
    "        node.set_label(self.target.iloc[target_ids].mode().iloc[0])\n",
    "\n",
    "    def entropy(self,ids):\n",
    "        if len(ids) == 0: return 0\n",
    "        freq = np.array(self.target.iloc[ids].value_counts()) # the array with the number of the occurrences of each value                  \n",
    "        freq=freq[freq!=0]  #   delete 0 element(can't use in logarit function)\n",
    "        prob=freq/float(np.sum(freq))  \n",
    "        return -np.sum(prob*np.log(prob)) # apply entropy function\n",
    "    \n",
    "    def predict(self,new_data):\n",
    "        npoints=new_data.count().iloc[0]\n",
    "        labels=[None]*npoints\n",
    "        for n in range(npoints):\n",
    "            x=new_data.iloc[n,:]\n",
    "            node=self.root\n",
    "            while node.children:    # recurive until reach leaf node\n",
    "                node=node.children[node.val_chosen.index(x[node.split_attribute])]\n",
    "            labels[n]=node.label\n",
    "        return labels\n",
    "def arrcuracy(model,X,y):\n",
    "    yhat=model.predict(X)\n",
    "    sum=np.sum(np.where(y==yhat,1,0))\n",
    "    return sum/len(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4024, 16)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('Breast_Cancer.csv')\n",
    "X = df1.iloc[:, :-1]\n",
    "y = df1.iloc[:, -1]\n",
    "df1.head()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8655566600397614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1=decision_tree_id3(max_depth=10,min_sample_split=3)\n",
    "model1.optimizer_step(X,y)\n",
    "print(arrcuracy(model1,X,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenvt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
